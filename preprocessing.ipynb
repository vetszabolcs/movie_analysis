{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a5ec38f",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be862203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E\n",
      "z\n",
      " \n",
      "e\n",
      "g\n",
      "y\n",
      " \n",
      "s\n",
      "z\n",
      "ö\n",
      "v\n",
      "e\n",
      "g\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for i in \"Ez egy szöveg.\":\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d258e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1, 2, 3, 4][0]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac9a9693",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'is', 'a', 'simple', 'sentence.']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This is a simple sentence.\"\n",
    "text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78f14a96",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'is', 'a', 'simple', 'sentence']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.replace(\".\", \" \").split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52cc3707",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "text = \"This is a simple sentence, isn't it?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b3f3a77",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'is', 'a', 'simple', 'sentence', '', \"isn't\", 'it', '']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from re import split\n",
    "split(\" |,|\\?\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cbcff1e",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "tokenized = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3307701c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized.count(\"This\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "312f0c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(\"This is this is that\".lower()).count(\"this\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e15d5f1",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e5e8f1e",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download(\"omw-1.4\")\n",
    "# nltk.download(\"punkt\")\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509c30dc",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba5ddffd",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f76bc475",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word', 'word', 'walk', 'walk', 'walk', 'happi', 'happier']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [\"word\", \"words\", \"walk\", \"walks\", \"walking\", \"happy\", \"happier\"]\n",
    "[stemmer.stem(w) for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "900ca4da",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wa'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"was\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9166289c",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'better'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"better\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff022bb1",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "116c570a",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word', 'word', 'walk', 'walk', 'walking', 'happy', 'happier']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "[lemmatizer.lemmatize(w) for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d8ab297",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happy'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"happier\", pos=wordnet.ADJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81a86d80",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"was\", pos=wordnet.VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b98bfca",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'be'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(wordnet.VERB)\n",
    "lemmatizer.lemmatize(\"was\", pos=\"v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65920c9d",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Spaghetti of lexical categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a745bcb",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nltk.pos_tag</th>\n",
       "      <th>wordnet.postag</th>\n",
       "      <th>string parameter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RB</td>\n",
       "      <td>ADVERB</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NN, PRP, etc.</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nltk.pos_tag wordnet.postag string parameter\n",
       "0             JJ            ADJ                a\n",
       "1             VB           VERB                v\n",
       "2             RB         ADVERB                r\n",
       "3  NN, PRP, etc.           NOUN                n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "DataFrame([[\"JJ\", \"ADJ\", \"a\"],\n",
    "           [\"VB\", \"VERB\", \"v\"],\n",
    "           [\"RB\", \"ADVERB\", \"r\"],\n",
    "           [\"NN, PRP, etc.\", \"NOUN\", \"n\"]],\n",
    "          columns=[\"nltk.pos_tag\", \"wordnet.postag\", \"string parameter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6d830f0",
   "metadata": {
    "code_folding": [],
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "class Lemmatizer(WordNetLemmatizer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.POS_DICT = {\"J\": \"a\",\n",
    "                    \"V\": \"v\",\n",
    "                    \"N\": \"n\",\n",
    "                    \"R\": \"r\"\n",
    "                   }\n",
    "        \n",
    "    def __call__(self, text):\n",
    "        words = nltk.word_tokenize(text)\n",
    "        keys = [tag[1][0] for tag in nltk.pos_tag(words)]\n",
    "        pos_tags = [self.POS_DICT[k] if k in self.POS_DICT.keys() else \"n\" for k in keys]\n",
    "        lemmas = [self.lemmatize(word, tag) for (word, tag) in zip(words, pos_tags)]\n",
    "        return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "059345ec",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A ball fell from a tree? Knocking on heaven's door? Open the door please Eye for an eye Donald Trump is closing the gates\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = ['A ball fell from a tree?', \"Knocking on heaven's door?\",\n",
    "         'Open the door please', 'Eye for an eye', 'Donald Trump is closing the gates']\n",
    "\n",
    "text = \" \".join(texts)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bf1367a",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'ball',\n",
       " 'fell',\n",
       " 'from',\n",
       " 'a',\n",
       " 'tree',\n",
       " '?',\n",
       " 'Knocking',\n",
       " 'on',\n",
       " 'heaven',\n",
       " \"'s\",\n",
       " 'door',\n",
       " '?',\n",
       " 'Open',\n",
       " 'the',\n",
       " 'door',\n",
       " 'please',\n",
       " 'Eye',\n",
       " 'for',\n",
       " 'an',\n",
       " 'eye',\n",
       " 'Donald',\n",
       " 'Trump',\n",
       " 'be',\n",
       " 'close',\n",
       " 'the',\n",
       " 'gate']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = Lemmatizer()\n",
    "lemmatizer(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f532c93",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1236f46",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\witen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c17df94",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"english\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "79348007",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'ahogy',\n",
       " 'ahol',\n",
       " 'aki',\n",
       " 'akik',\n",
       " 'akkor',\n",
       " 'alatt',\n",
       " 'által',\n",
       " 'általában',\n",
       " 'amely']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"hungarian\")[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a037e74f",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Text Vectoriztaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71bb0b35",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f4353e47",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['A', 'ball', 'fell', 'from', 'a', 'tree?'],\n",
       " ['Knocking', 'on', \"heaven's\", 'door?'],\n",
       " ['Open', 'the', 'door', 'please'],\n",
       " ['Eye', 'for', 'an', 'eye'],\n",
       " ['Donald', 'Trump', 'is', 'closing', 'the', 'gates']]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_split = [t.split() for t in texts]\n",
    "texts_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9d113947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Knocking', 'on', \"heaven's\", 'door?']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_split[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41aa2bb7",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['A', 'ball', 'fell', 'from', 'a', 'tree', '?'],\n",
       " ['Knocking', 'on', 'heaven', \"'s\", 'door', '?'],\n",
       " ['Open', 'the', 'door', 'please'],\n",
       " ['Eye', 'for', 'an', 'eye'],\n",
       " ['Donald', 'Trump', 'be', 'close', 'the', 'gate']]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized = [lemmatizer(t) for t in texts]\n",
    "lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec86ce83",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['?',\n",
       " \"'s\",\n",
       " 'open',\n",
       " 'the',\n",
       " 'gates',\n",
       " 'door',\n",
       " 'from',\n",
       " 'eye',\n",
       " 'ball',\n",
       " 'fell',\n",
       " 'for',\n",
       " 'please',\n",
       " 'trump',\n",
       " 'heaven',\n",
       " 'an',\n",
       " 'closing',\n",
       " 'tree',\n",
       " 'a',\n",
       " 'donald',\n",
       " 'is',\n",
       " 'knocking',\n",
       " 'on']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(\" \".join(texts).lower())\n",
    "uniqs = list(set(tokens))\n",
    "uniqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f5fa9d6e",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 22)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = np.zeros(shape=(len(texts), len(uniqs)))\n",
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e174c894",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>?</th>\n",
       "      <th>'s</th>\n",
       "      <th>open</th>\n",
       "      <th>the</th>\n",
       "      <th>gates</th>\n",
       "      <th>door</th>\n",
       "      <th>from</th>\n",
       "      <th>eye</th>\n",
       "      <th>ball</th>\n",
       "      <th>fell</th>\n",
       "      <th>...</th>\n",
       "      <th>trump</th>\n",
       "      <th>heaven</th>\n",
       "      <th>an</th>\n",
       "      <th>closing</th>\n",
       "      <th>tree</th>\n",
       "      <th>a</th>\n",
       "      <th>donald</th>\n",
       "      <th>is</th>\n",
       "      <th>knocking</th>\n",
       "      <th>on</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ?   's  open  the  gates  door  from  eye  ball  fell  ...  trump  \\\n",
       "0  1.0  0.0   0.0  0.0    0.0   0.0   1.0  0.0   1.0   1.0  ...    0.0   \n",
       "1  1.0  1.0   0.0  0.0    0.0   1.0   0.0  0.0   0.0   0.0  ...    0.0   \n",
       "2  0.0  0.0   1.0  1.0    0.0   1.0   0.0  0.0   0.0   0.0  ...    0.0   \n",
       "3  0.0  0.0   0.0  0.0    0.0   0.0   0.0  2.0   0.0   0.0  ...    0.0   \n",
       "4  0.0  0.0   0.0  1.0    0.0   0.0   0.0  0.0   0.0   0.0  ...    1.0   \n",
       "\n",
       "   heaven   an  closing  tree    a  donald   is  knocking   on  \n",
       "0     0.0  0.0      0.0   1.0  2.0     0.0  0.0       0.0  0.0  \n",
       "1     1.0  0.0      0.0   0.0  0.0     0.0  0.0       1.0  1.0  \n",
       "2     0.0  0.0      0.0   0.0  0.0     0.0  0.0       0.0  0.0  \n",
       "3     0.0  1.0      0.0   0.0  0.0     0.0  0.0       0.0  0.0  \n",
       "4     0.0  0.0      0.0   0.0  0.0     1.0  0.0       0.0  0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(mat.shape[0]):\n",
    "    for j in range(mat.shape[1]):\n",
    "        count = [l.lower() for l in lemmatized[i]].count(uniqs[j])\n",
    "        mat[i,j] = count\n",
    "\n",
    "pd.DataFrame(mat, columns=uniqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2410698",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Sklearn's CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "46e61335",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "24acb0c0",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A ball fell from a tree?',\n",
       " \"Knocking on heaven's door?\",\n",
       " 'Open the door please',\n",
       " 'Eye for an eye',\n",
       " 'Donald Trump is closing the gates']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ccd74b81",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ball</th>\n",
       "      <th>closing</th>\n",
       "      <th>donald</th>\n",
       "      <th>door</th>\n",
       "      <th>eye</th>\n",
       "      <th>fell</th>\n",
       "      <th>gates</th>\n",
       "      <th>heaven</th>\n",
       "      <th>knocking</th>\n",
       "      <th>open</th>\n",
       "      <th>tree</th>\n",
       "      <th>trump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ball  closing  donald  door  eye  fell  gates  heaven  knocking  open  \\\n",
       "0     1        0       0     0    0     1      0       0         0     0   \n",
       "1     0        0       0     1    0     0      0       1         1     0   \n",
       "2     0        0       0     1    0     0      0       0         0     1   \n",
       "3     0        0       0     0    2     0      0       0         0     0   \n",
       "4     0        1       1     0    0     0      1       0         0     0   \n",
       "\n",
       "   tree  trump  \n",
       "0     1      0  \n",
       "1     0      0  \n",
       "2     0      0  \n",
       "3     0      0  \n",
       "4     0      1  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "mat = vectorizer.fit_transform(texts)\n",
    "\n",
    "pd.DataFrame(mat.toarray(), columns = vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3abfc293",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'21.7% is not 0'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent = (mat != 0).sum() / (mat.shape[0] * mat.shape[1])\n",
    "f\"{round(percent, 3)*100}% is not 0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea16c07",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Predicting outcome (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9e03d694",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8e9fc01b",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"BBC News Train.csv\")\n",
    "X = df[\"Text\"]\n",
    "Y = df[\"Category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0fc95adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['business', 'tech', 'politics', 'sport', 'entertainment'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,2].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9e8b7d7b",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1192,) (298,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6cad7cd6",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "87f7860f",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "X_train_s = vectorizer.fit_transform(X_train)\n",
    "X_test_s = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "32860c22",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "svm = SVC(kernel=\"linear\").fit(X_train_s, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "376abe3d",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.score(X_train_s, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d8af1bc0",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9798657718120806"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.score(X_test_s, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "06f7d63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business</th>\n",
       "      <th>tech</th>\n",
       "      <th>politics</th>\n",
       "      <th>sport</th>\n",
       "      <th>entertainment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>politics</th>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sport</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983051</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entertainment</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               business      tech  politics     sport  entertainment\n",
       "business       0.972222  0.000000  0.018519  0.016949            0.0\n",
       "tech           0.000000  0.983607  0.018519  0.000000            0.0\n",
       "politics       0.027778  0.000000  0.962963  0.000000            0.0\n",
       "sport          0.000000  0.000000  0.000000  0.983051            0.0\n",
       "entertainment  0.000000  0.016393  0.000000  0.000000            1.0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svm.predict(X_test_s)\n",
    "\n",
    "pd.DataFrame(confusion_matrix(Y_test, y_pred, normalize=\"pred\"),\n",
    "             columns=df[\"Category\"].unique(), index=df[\"Category\"].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1119c6a9",
   "metadata": {},
   "source": [
    "## With lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "45aea462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fd163dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.326080322265625"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", tokenizer=Lemmatizer())\n",
    "X_train_l = vectorizer.fit_transform(X_train)\n",
    "X_test_l = vectorizer.transform(X_test)\n",
    "lemma_time = time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a5129598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.751677852348993"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lemma_time * (15000/len(df)))/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "031165d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm2 = SVC(kernel=\"linear\").fit(X_train_l, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "698ebeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm2.score(X_train_l, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2008c3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9932885906040269"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm2.score(X_test_l, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "81b47f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business</th>\n",
       "      <th>tech</th>\n",
       "      <th>politics</th>\n",
       "      <th>sport</th>\n",
       "      <th>entertainment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>politics</th>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sport</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.983051</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entertainment</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               business  tech  politics     sport  entertainment\n",
       "business       0.986301   0.0       0.0  0.000000            0.0\n",
       "tech           0.000000   1.0       0.0  0.000000            0.0\n",
       "politics       0.013699   0.0       1.0  0.016949            0.0\n",
       "sport          0.000000   0.0       0.0  0.983051            0.0\n",
       "entertainment  0.000000   0.0       0.0  0.000000            1.0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svm2.predict(X_test_l)\n",
    "pd.DataFrame(confusion_matrix(Y_test, y_pred, normalize=\"pred\"),\n",
    "                              columns=df[\"Category\"].unique(), index=df[\"Category\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362ec720",
   "metadata": {},
   "source": [
    "## With stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "350ca005",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stemmer(nltk.stem.porter.PorterStemmer):\n",
    "    def __call__(self, text):\n",
    "        tokens = word_tokenize(text)\n",
    "        stemmed = [self.stem(t) for t in tokens]\n",
    "        return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3fce4543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", tokenizer=Stemmer())\n",
    "X_train_st = vectorizer.fit_transform(X_train)\n",
    "X_test_st = vectorizer.transform(X_test)\n",
    "stopw_time = time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "66621e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0235818104455934"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(stopw_time * (15000/len(df)))/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "44c2ac4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'worldcom ex-boss launches defence lawyers defending former worldcom chief bernie ebbers against a battery of fraud charges have called a company whistleblower as their first witness.  cynthia cooper  worldcom s ex-head of internal accounting  alerted directors to irregular accounting practices at the us telecoms giant in 2002. her warnings led to the collapse of the firm following the discovery of an $11bn (£5.7bn) accounting fraud. mr ebbers has pleaded not guilty to charges of fraud and conspiracy.  prosecution lawyers have argued that mr ebbers orchestrated a series of accounting tricks at worldcom  ordering employees to hide expenses and inflate revenues to meet wall street earnings estimates. but ms cooper  who now runs her own consulting business  told a jury in new york on wednesday that external auditors arthur andersen had approved worldcom s accounting in early 2001 and 2002. she said andersen had given a  green light  to the procedures and practices used by worldcom. mr ebber s lawyers have said he was unaware of the fraud  arguing that auditors did not alert him to any problems.  ms cooper also said that during shareholder meetings mr ebbers often passed over technical questions to the company s finance chief  giving only  brief  answers himself. the prosecution s star witness  former worldcom financial chief scott sullivan  has said that mr ebbers ordered accounting adjustments at the firm  telling him to  hit our books . however  ms cooper said mr sullivan had not mentioned  anything uncomfortable  about worldcom s accounting during a 2001 audit committee meeting. mr ebbers could face a jail sentence of 85 years if convicted of all the charges he is facing. worldcom emerged from bankruptcy protection in 2004  and is now known as mci. last week  mci agreed to a buyout by verizon communications in a deal valued at $6.75bn.'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "13cc9ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm3 = SVC(kernel=\"linear\").fit(X_train_st, Y_train)\n",
    "svm3.score(X_train_st, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3b230bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9865771812080537"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm3.score(X_test_st, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd09c62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_s = svm3.predict(X_test_s)\n",
    "confusion_matrix(Y_test, y_pred_s, normalize=\"pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af27b67c",
   "metadata": {},
   "source": [
    "# Predicting unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "48e098b1",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"BBC News Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c84b3d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1018</td>\n",
       "      <td>qpr keeper day heads for preston queens park r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1319</td>\n",
       "      <td>software watching while you work software that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1138</td>\n",
       "      <td>d arcy injury adds to ireland woe gordon d arc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459</td>\n",
       "      <td>india s reliance family feud heats up the ongo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020</td>\n",
       "      <td>boro suffer morrison injury blow middlesbrough...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>1923</td>\n",
       "      <td>eu to probe alitalia  state aid  the european ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>373</td>\n",
       "      <td>u2 to play at grammy awards show irish rock ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>1704</td>\n",
       "      <td>sport betting rules in spotlight a group of mp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>206</td>\n",
       "      <td>alfa romeos  to get gm engines  fiat is to sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>471</td>\n",
       "      <td>citizenship event for 18s touted citizenship c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>735 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ArticleId                                               Text\n",
       "0         1018  qpr keeper day heads for preston queens park r...\n",
       "1         1319  software watching while you work software that...\n",
       "2         1138  d arcy injury adds to ireland woe gordon d arc...\n",
       "3          459  india s reliance family feud heats up the ongo...\n",
       "4         1020  boro suffer morrison injury blow middlesbrough...\n",
       "..         ...                                                ...\n",
       "730       1923  eu to probe alitalia  state aid  the european ...\n",
       "731        373  u2 to play at grammy awards show irish rock ba...\n",
       "732       1704  sport betting rules in spotlight a group of mp...\n",
       "733        206  alfa romeos  to get gm engines  fiat is to sto...\n",
       "734        471  citizenship event for 18s touted citizenship c...\n",
       "\n",
       "[735 rows x 2 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "abcc9b0f",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "test[\"Prediction\"] = svm3.predict(vectorizer.transform(test[\"Text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ea7f0b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1018</td>\n",
       "      <td>qpr keeper day heads for preston queens park r...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1319</td>\n",
       "      <td>software watching while you work software that...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1138</td>\n",
       "      <td>d arcy injury adds to ireland woe gordon d arc...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459</td>\n",
       "      <td>india s reliance family feud heats up the ongo...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020</td>\n",
       "      <td>boro suffer morrison injury blow middlesbrough...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>1923</td>\n",
       "      <td>eu to probe alitalia  state aid  the european ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>373</td>\n",
       "      <td>u2 to play at grammy awards show irish rock ba...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>1704</td>\n",
       "      <td>sport betting rules in spotlight a group of mp...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>206</td>\n",
       "      <td>alfa romeos  to get gm engines  fiat is to sto...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>471</td>\n",
       "      <td>citizenship event for 18s touted citizenship c...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>735 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ArticleId                                               Text  \\\n",
       "0         1018  qpr keeper day heads for preston queens park r...   \n",
       "1         1319  software watching while you work software that...   \n",
       "2         1138  d arcy injury adds to ireland woe gordon d arc...   \n",
       "3          459  india s reliance family feud heats up the ongo...   \n",
       "4         1020  boro suffer morrison injury blow middlesbrough...   \n",
       "..         ...                                                ...   \n",
       "730       1923  eu to probe alitalia  state aid  the european ...   \n",
       "731        373  u2 to play at grammy awards show irish rock ba...   \n",
       "732       1704  sport betting rules in spotlight a group of mp...   \n",
       "733        206  alfa romeos  to get gm engines  fiat is to sto...   \n",
       "734        471  citizenship event for 18s touted citizenship c...   \n",
       "\n",
       "        Prediction  \n",
       "0            sport  \n",
       "1             tech  \n",
       "2            sport  \n",
       "3         business  \n",
       "4            sport  \n",
       "..             ...  \n",
       "730       business  \n",
       "731  entertainment  \n",
       "732       business  \n",
       "733       business  \n",
       "734       politics  \n",
       "\n",
       "[735 rows x 3 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2fef10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
